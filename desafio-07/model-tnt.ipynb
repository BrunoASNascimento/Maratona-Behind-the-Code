{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "model-tnt.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "56yXBQMCpUbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Insira seu project token aqui\n",
        "# d5940933-059f-47df-88cc-00baf7d03380-bluemix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "dEzFPkFmpUbz",
        "colab_type": "text"
      },
      "source": [
        "# MARATONA BEHIND THE CODE 2020\n",
        "\n",
        "## DESAFIO 7 - TNT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkvvOyVipUb0",
        "colab_type": "text"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqIhc66ixVv-",
        "colab_type": "text"
      },
      "source": [
        "# Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W-5zAWLxZdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -Iv pandas==0.25.0\n",
        "!sudo apt-get install build-essential swig\n",
        "!curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip install\n",
        "!pip install auto-sklearn\n",
        "!pip install arff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTdRZY3KxFlX",
        "colab_type": "text"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3g5SDXAxFB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import autosklearn.classification\n",
        "from autosklearn.experimental.askl2 import AutoSklearn2Classifier\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0peqkoLR3r8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b5c484f-bf22-4953-d17a-536c3ce03eb2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zfgsg_rpUcG",
        "colab_type": "text"
      },
      "source": [
        "## Download dos conjuntos de dados em formato .csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw-dHxsfpUcP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d72c10e3-64fd-49b1-e0bd-ca6fbcb9f04f"
      },
      "source": [
        "# Insira aqui o pandasDataFrame.\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/BrunoASNascimento/Maratona-Behind-the-Code-2020/master/desafio-07/data/data-set.csv')\n",
        "df.head()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tempo</th>\n",
              "      <th>Estação</th>\n",
              "      <th>LAT</th>\n",
              "      <th>LONG</th>\n",
              "      <th>Movimentação</th>\n",
              "      <th>Original_473</th>\n",
              "      <th>Original_269</th>\n",
              "      <th>Zero</th>\n",
              "      <th>Maçã-Verde</th>\n",
              "      <th>Tangerina</th>\n",
              "      <th>Citrus</th>\n",
              "      <th>Açaí-Guaraná</th>\n",
              "      <th>Pêssego</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-8-1</td>\n",
              "      <td>Tamanduateí</td>\n",
              "      <td>-23.5929</td>\n",
              "      <td>-46.5897</td>\n",
              "      <td>50677</td>\n",
              "      <td>29</td>\n",
              "      <td>36</td>\n",
              "      <td>44</td>\n",
              "      <td>41</td>\n",
              "      <td>27</td>\n",
              "      <td>42</td>\n",
              "      <td>9</td>\n",
              "      <td>38</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-10-20</td>\n",
              "      <td>Fradique Coutinho</td>\n",
              "      <td>-23.5661</td>\n",
              "      <td>-46.6841</td>\n",
              "      <td>34880</td>\n",
              "      <td>23</td>\n",
              "      <td>65</td>\n",
              "      <td>18</td>\n",
              "      <td>37</td>\n",
              "      <td>30</td>\n",
              "      <td>20</td>\n",
              "      <td>36</td>\n",
              "      <td>28</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-9-23</td>\n",
              "      <td>Tamanduateí</td>\n",
              "      <td>-23.5929</td>\n",
              "      <td>-46.5897</td>\n",
              "      <td>50873</td>\n",
              "      <td>52</td>\n",
              "      <td>17</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>35</td>\n",
              "      <td>23</td>\n",
              "      <td>26</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-11-29</td>\n",
              "      <td>Fradique Coutinho</td>\n",
              "      <td>-23.5661</td>\n",
              "      <td>-46.6841</td>\n",
              "      <td>36207</td>\n",
              "      <td>64</td>\n",
              "      <td>44</td>\n",
              "      <td>65</td>\n",
              "      <td>36</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>43</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-10-27</td>\n",
              "      <td>Tamanduateí</td>\n",
              "      <td>-23.5929</td>\n",
              "      <td>-46.5897</td>\n",
              "      <td>50176</td>\n",
              "      <td>60</td>\n",
              "      <td>52</td>\n",
              "      <td>26</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>31</td>\n",
              "      <td>18</td>\n",
              "      <td>REABASTECER</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Tempo            Estação      LAT  ...  Açaí-Guaraná  Pêssego       TARGET\n",
              "0    2019-8-1        Tamanduateí -23.5929  ...             9       38       NORMAL\n",
              "1  2019-10-20  Fradique Coutinho -23.5661  ...            36       28       NORMAL\n",
              "2   2019-9-23        Tamanduateí -23.5929  ...            23       26       NORMAL\n",
              "3  2019-11-29  Fradique Coutinho -23.5661  ...            10       43       NORMAL\n",
              "4  2019-10-27        Tamanduateí -23.5929  ...            31       18  REABASTECER\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GY4YkKvyBdj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "401e0bb4-fa5f-45e6-a45d-5d53d4044177"
      },
      "source": [
        "df['TARGET'].drop_duplicates()\n",
        "df.loc[df['TARGET']=='NORMAL'] = 1\n",
        "df.loc[df['TARGET']=='REABASTECER'] = 0\n",
        "df.head()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tempo</th>\n",
              "      <th>Estação</th>\n",
              "      <th>LAT</th>\n",
              "      <th>LONG</th>\n",
              "      <th>Movimentação</th>\n",
              "      <th>Original_473</th>\n",
              "      <th>Original_269</th>\n",
              "      <th>Zero</th>\n",
              "      <th>Maçã-Verde</th>\n",
              "      <th>Tangerina</th>\n",
              "      <th>Citrus</th>\n",
              "      <th>Açaí-Guaraná</th>\n",
              "      <th>Pêssego</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tempo  Estação  LAT  LONG  ...  Citrus  Açaí-Guaraná  Pêssego  TARGET\n",
              "0      1        1  1.0   1.0  ...       1             1        1       1\n",
              "1      1        1  1.0   1.0  ...       1             1        1       1\n",
              "2      1        1  1.0   1.0  ...       1             1        1       1\n",
              "3      1        1  1.0   1.0  ...       1             1        1       1\n",
              "4      0        0  0.0   0.0  ...       0             0        0       0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pawBiBJ5p64E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "5a81d693-6dd3-4761-e68c-7769aa4db935"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5099 entries, 0 to 5098\n",
            "Data columns (total 14 columns):\n",
            "Tempo           5099 non-null int64\n",
            "Estação         5099 non-null int64\n",
            "LAT             5099 non-null float64\n",
            "LONG            5099 non-null float64\n",
            "Movimentação    5099 non-null int64\n",
            "Original_473    5099 non-null int64\n",
            "Original_269    5099 non-null int64\n",
            "Zero            5099 non-null int64\n",
            "Maçã-Verde      5099 non-null int64\n",
            "Tangerina       5099 non-null int64\n",
            "Citrus          5099 non-null int64\n",
            "Açaí-Guaraná    5099 non-null int64\n",
            "Pêssego         5099 non-null int64\n",
            "TARGET          5099 non-null int64\n",
            "dtypes: float64(2), int64(12)\n",
            "memory usage: 557.8 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OlHK2pVpUcU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6c096071-1372-4548-b691-2d6a4057c64f"
      },
      "source": [
        "df_training_dataset = df\n",
        "df_training_dataset.tail()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tempo</th>\n",
              "      <th>Estação</th>\n",
              "      <th>LAT</th>\n",
              "      <th>LONG</th>\n",
              "      <th>Movimentação</th>\n",
              "      <th>Original_473</th>\n",
              "      <th>Original_269</th>\n",
              "      <th>Zero</th>\n",
              "      <th>Maçã-Verde</th>\n",
              "      <th>Tangerina</th>\n",
              "      <th>Citrus</th>\n",
              "      <th>Açaí-Guaraná</th>\n",
              "      <th>Pêssego</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5094</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5095</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5096</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5097</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5098</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Tempo  Estação  LAT  LONG  ...  Citrus  Açaí-Guaraná  Pêssego  TARGET\n",
              "5094      1        1  1.0   1.0  ...       1             1        1       1\n",
              "5095      1        1  1.0   1.0  ...       1             1        1       1\n",
              "5096      0        0  0.0   0.0  ...       0             0        0       0\n",
              "5097      1        1  1.0   1.0  ...       1             1        1       1\n",
              "5098      1        1  1.0   1.0  ...       1             1        1       1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hfwU2pXpUcb",
        "colab_type": "text"
      },
      "source": [
        "Sobre o arquivo \"training_dataset.csv\", temos algumas informações gerais sobre os pontos de vendas da TNT:\n",
        "\n",
        "**Tempo**\n",
        "\n",
        "**Estação**\n",
        "\n",
        "**LAT**\n",
        "\n",
        "**LONG**\n",
        "\n",
        "**Movimentação**\n",
        "\n",
        "**Original_473**\n",
        "\n",
        "**Original_269**\n",
        "\n",
        "**Zero**\n",
        "\n",
        "**Maçã-Verde**\n",
        "\n",
        "**Tangerina**\n",
        "\n",
        "**Citrus**\n",
        "\n",
        "**Açaí-Guaraná**\n",
        "\n",
        "**Pêssego**\n",
        "\n",
        "**TARGET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXStAqYxpUcb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "36a1c031-ed04-435e-eaf5-22efd84902fd"
      },
      "source": [
        "df_training_dataset.info()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5099 entries, 0 to 5098\n",
            "Data columns (total 14 columns):\n",
            "Tempo           5099 non-null int64\n",
            "Estação         5099 non-null int64\n",
            "LAT             5099 non-null float64\n",
            "LONG            5099 non-null float64\n",
            "Movimentação    5099 non-null int64\n",
            "Original_473    5099 non-null int64\n",
            "Original_269    5099 non-null int64\n",
            "Zero            5099 non-null int64\n",
            "Maçã-Verde      5099 non-null int64\n",
            "Tangerina       5099 non-null int64\n",
            "Citrus          5099 non-null int64\n",
            "Açaí-Guaraná    5099 non-null int64\n",
            "Pêssego         5099 non-null int64\n",
            "TARGET          5099 non-null int64\n",
            "dtypes: float64(2), int64(12)\n",
            "memory usage: 557.8 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQUNMjFkpUcf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "d0b23f2d-d230-419c-b226-7fdd5e485905"
      },
      "source": [
        "df_training_dataset.nunique()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tempo           2\n",
              "Estação         2\n",
              "LAT             2\n",
              "LONG            2\n",
              "Movimentação    2\n",
              "Original_473    2\n",
              "Original_269    2\n",
              "Zero            2\n",
              "Maçã-Verde      2\n",
              "Tangerina       2\n",
              "Citrus          2\n",
              "Açaí-Guaraná    2\n",
              "Pêssego         2\n",
              "TARGET          2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28Sxcqk1pUck",
        "colab_type": "text"
      },
      "source": [
        "<hr>\n",
        "\n",
        "## Detalhamento do desafio: classificação binária\n",
        "\n",
        "Este é um desafio cujo objetivo de negócio é a segmentação dos usuários de aplicativo de um banco. Para tal, podemos utilizar duas abordagens: aprendizado de máquina supervisionado (classificação) ou não-supervisionado (clustering). Neste desafio será aplicada a classificação, pois é disponível um dataset já com \"labels\", ou em outras palavras, já com exemplos de dados juntamente com a variável alvo.\n",
        "\n",
        "Na biblioteca scikit-learn temos diversos algoritmos para classificação. O participante é livre para utilizar o framework que desejar para completar esse desafio.\n",
        "\n",
        "Neste notebook será mostrado um exeplo de uso do algoritmo \"Decision Tree\" para classificar parte dos estudantes em seis diferentes perfís."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG3Jv9K8pUcl",
        "colab_type": "text"
      },
      "source": [
        "# Atenção!\n",
        "\n",
        "A coluna-alvo neste desafio é a coluna ``TARGET``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4IwnSRSpUcm",
        "colab_type": "text"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4xWiL9VpUcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d92EtiVrpUcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkuE1txJpUc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuMrGAWcpUc7",
        "colab_type": "text"
      },
      "source": [
        "## Pre-processando o dataset antes do treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ0K_JECpUc8",
        "colab_type": "text"
      },
      "source": [
        "### Processando valores NaN com o SimpleImputer do sklearn\n",
        "\n",
        "Para os valores NaN, usaremos a substituição pela constante 0 como **exemplo**.\n",
        "\n",
        "Você pode escolher a estratégia que achar melhor para tratar os valores nulos :)\n",
        "\n",
        "Docs: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html?highlight=simpleimputer#sklearn.impute.SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6Hi42oUpUc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "impute_zeros = SimpleImputer(\n",
        "    missing_values=np.nan,\n",
        "    strategy='constant',\n",
        "    fill_value=0,\n",
        "    verbose=0,\n",
        "    copy=True\n",
        ")"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S_g_3x_pUdB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fe50504c-19b5-43aa-fa03-cfd6e7e83726"
      },
      "source": [
        "# Exibindo os dados ausentes do conjunto de dados antes da primeira transformação (df)\n",
        "print(\"Valores nulos no df_training_dataset antes da transformação SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset.isnull().sum(axis = 0)))\n",
        "\n",
        "# Aplicando a transformação ``SimpleImputer`` no conjunto de dados base\n",
        "impute_zeros.fit(X=df_training_dataset)\n",
        "\n",
        "# Reconstruindo um Pandas DataFrame com os resultados\n",
        "df_training_dataset_imputed = pd.DataFrame.from_records(\n",
        "    data=impute_zeros.transform(\n",
        "        X=df_training_dataset\n",
        "    ),\n",
        "    columns=df_training_dataset.columns\n",
        ")\n",
        "\n",
        "# Exibindo os dados ausentes do conjunto de dados após a primeira transformação (df)\n",
        "print(\"Valores nulos no df_training_dataset após a transformação SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset_imputed.isnull().sum(axis = 0)))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valores nulos no df_training_dataset antes da transformação SimpleImputer: \n",
            "\n",
            "Tempo           0\n",
            "Estação         0\n",
            "LAT             0\n",
            "LONG            0\n",
            "Movimentação    0\n",
            "Original_473    0\n",
            "Original_269    0\n",
            "Zero            0\n",
            "Maçã-Verde      0\n",
            "Tangerina       0\n",
            "Citrus          0\n",
            "Açaí-Guaraná    0\n",
            "Pêssego         0\n",
            "TARGET          0\n",
            "dtype: int64\n",
            "\n",
            "Valores nulos no df_training_dataset após a transformação SimpleImputer: \n",
            "\n",
            "Tempo           0\n",
            "Estação         0\n",
            "LAT             0\n",
            "LONG            0\n",
            "Movimentação    0\n",
            "Original_473    0\n",
            "Original_269    0\n",
            "Zero            0\n",
            "Maçã-Verde      0\n",
            "Tangerina       0\n",
            "Citrus          0\n",
            "Açaí-Guaraná    0\n",
            "Pêssego         0\n",
            "TARGET          0\n",
            "dtype: int64\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIi7BAsNpUdE",
        "colab_type": "text"
      },
      "source": [
        "### Eliminando colunas indesejadas\n",
        "\n",
        "Vamos **demonstrar** abaixo como usar o método **DataFrame.drop()**.\n",
        "\n",
        "Docs: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stnkEpj4pUdF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d0364d89-17d6-400f-b290-af99b591992e"
      },
      "source": [
        "df_training_dataset_imputed.tail()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tempo</th>\n",
              "      <th>Estação</th>\n",
              "      <th>LAT</th>\n",
              "      <th>LONG</th>\n",
              "      <th>Movimentação</th>\n",
              "      <th>Original_473</th>\n",
              "      <th>Original_269</th>\n",
              "      <th>Zero</th>\n",
              "      <th>Maçã-Verde</th>\n",
              "      <th>Tangerina</th>\n",
              "      <th>Citrus</th>\n",
              "      <th>Açaí-Guaraná</th>\n",
              "      <th>Pêssego</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5094</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5095</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5096</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5097</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5098</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Tempo  Estação  LAT  LONG  ...  Citrus  Açaí-Guaraná  Pêssego  TARGET\n",
              "5094    1.0      1.0  1.0   1.0  ...     1.0           1.0      1.0     1.0\n",
              "5095    1.0      1.0  1.0   1.0  ...     1.0           1.0      1.0     1.0\n",
              "5096    0.0      0.0  0.0   0.0  ...     0.0           0.0      0.0     0.0\n",
              "5097    1.0      1.0  1.0   1.0  ...     1.0           1.0      1.0     1.0\n",
              "5098    1.0      1.0  1.0   1.0  ...     1.0           1.0      1.0     1.0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF306ghapUdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_training_dataset_rmcolumns = df_training_dataset_imputed.drop(columns=['Tempo', 'Estação', 'LAT', 'LONG', 'Movimentação'], inplace=False)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuGTh3YhpUdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bcf07fb4-0bac-49a1-b09d-83f257b63a56"
      },
      "source": [
        "df_training_dataset_rmcolumns.tail()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Original_473</th>\n",
              "      <th>Original_269</th>\n",
              "      <th>Zero</th>\n",
              "      <th>Maçã-Verde</th>\n",
              "      <th>Tangerina</th>\n",
              "      <th>Citrus</th>\n",
              "      <th>Açaí-Guaraná</th>\n",
              "      <th>Pêssego</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5094</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5095</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5096</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5097</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5098</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Original_473  Original_269  Zero  ...  Açaí-Guaraná  Pêssego  TARGET\n",
              "5094           1.0           1.0   1.0  ...           1.0      1.0     1.0\n",
              "5095           1.0           1.0   1.0  ...           1.0      1.0     1.0\n",
              "5096           0.0           0.0   0.0  ...           0.0      0.0     0.0\n",
              "5097           1.0           1.0   1.0  ...           1.0      1.0     1.0\n",
              "5098           1.0           1.0   1.0  ...           1.0      1.0     1.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHSYVUVKpUdS",
        "colab_type": "text"
      },
      "source": [
        "# Atenção!\n",
        "\n",
        "As colunas removidas acima são apenas para fim de exemplo, você pode usar as colunas que quiser e inclusive criar novas colunas com dados que achar importantes!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgxBYxSPpUdT",
        "colab_type": "text"
      },
      "source": [
        "### Tratamento de de variáveis categóricas\n",
        "\n",
        "Como mencionado antes, os computadores não são bons com variáveis \"categóricas\" (ou strings).\n",
        "\n",
        "Dado uma coluna com variável categórica, o que podemos realizar é a codificação dessa coluna em múltiplas colunas contendo variáveis binárias. Esse processo é chamado de \"one-hot-encoding\" ou \"dummy encoding\". Se você não é familiarizado com esses termos, você pode pesquisar mais sobre isso na internet :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtccrtr4pUdU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d3dc3f9f-a06f-4a6b-d41c-d2aa1d6840bb"
      },
      "source": [
        "# Tratando variáveis categóricas com o método Pandas ``get_dummies()''\n",
        "# df_training = pd.get_dummies(df_training_dataset_rmcolumns, columns=['Variável a ser aplicado método getDumies()'])\n",
        "df_training = df_training_dataset_rmcolumns\n",
        "df_training.tail()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Original_473</th>\n",
              "      <th>Original_269</th>\n",
              "      <th>Zero</th>\n",
              "      <th>Maçã-Verde</th>\n",
              "      <th>Tangerina</th>\n",
              "      <th>Citrus</th>\n",
              "      <th>Açaí-Guaraná</th>\n",
              "      <th>Pêssego</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5094</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5095</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5096</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5097</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5098</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Original_473  Original_269  Zero  ...  Açaí-Guaraná  Pêssego  TARGET\n",
              "5094           1.0           1.0   1.0  ...           1.0      1.0     1.0\n",
              "5095           1.0           1.0   1.0  ...           1.0      1.0     1.0\n",
              "5096           0.0           0.0   0.0  ...           0.0      0.0     0.0\n",
              "5097           1.0           1.0   1.0  ...           1.0      1.0     1.0\n",
              "5098           1.0           1.0   1.0  ...           1.0      1.0     1.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkS_EZiMpUdX",
        "colab_type": "text"
      },
      "source": [
        "# Atenção!\n",
        "\n",
        "A coluna **TARGET** deve ser mantida como uma string. Você não precisa processar/codificar a variável-alvo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2ACNn_LpUdY",
        "colab_type": "text"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaO7sSyvpUdZ",
        "colab_type": "text"
      },
      "source": [
        "## Treinando um classificador com base em uma árvore de decisão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYGg9sL-pUdZ",
        "colab_type": "text"
      },
      "source": [
        "### Selecionando FEATURES e definindo a variável TARGET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0ydB6fwpUde",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8afd62e3-ce1f-48eb-830b-886a730b9ec0"
      },
      "source": [
        "df_training.columns"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Original_473', 'Original_269', 'Zero', 'Maçã-Verde', 'Tangerina',\n",
              "       'Citrus', 'Açaí-Guaraná', 'Pêssego', 'TARGET'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-_M3-rIpUdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = df_training[\n",
        "    [\n",
        "        'Original_473', 'Original_269', 'Zero', 'Maçã-Verde', 'Tangerina',\n",
        "       'Citrus', 'Açaí-Guaraná', 'Pêssego'\n",
        "    ]\n",
        "]\n",
        "target = df_training['TARGET']  ## NÃO TROQUE O NOME DA VARIÁVEL TARGET."
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxUbyJSkpUdl",
        "colab_type": "text"
      },
      "source": [
        "### Dividindo nosso conjunto de dados em conjuntos de treinamento e teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS5U_HkNpUdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=133)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOYJR3FtpUdv",
        "colab_type": "text"
      },
      "source": [
        "### Treinando"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw4KJYlwpUdw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb51fab8-ff15-4b80-98fc-52cda6b8193b"
      },
      "source": [
        "# Método para criar um árvore de decisão\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "dtc = AutoSklearn2Classifier().fit(X_train, y_train)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using no backup selector\n",
            "[WARNING] [2020-09-09 00:37:01,831:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 00:37:04,128:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 00:37:06,596:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 00:43:07,669:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 00:43:09,826:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 00:43:12,907:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 00:43:15,566:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 00:49:16,712:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 00:55:17,842:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 00:55:20,826:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:01:21,994:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:01:25,272:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:01:29,047:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:01:32,412:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:01:35,978:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:01:58,845:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:01:58,847:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:01:58,850:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:02,354:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:02,360:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:02,367:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:05,499:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:05,502:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:05,504:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:02:07,398:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:07,404:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:07,406:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:13,077:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:13,079:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:13,081:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:15,975:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:15,980:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:15,982:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:02:18,901:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:18,910:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:18,920:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:22,502:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:22,513:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:22,526:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:26,181:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:26,200:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:26,208:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:29,897:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:29,913:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:29,929:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:33,076:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:33,078:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:33,084:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:02:35,854:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:35,861:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:35,863:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:02:37,767:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:37,770:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:37,772:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:42,021:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:42,024:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:42,026:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:47,727:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:47,744:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:47,750:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:02:52,407:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:52,414:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:02:52,421:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:21,349:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:21,352:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:21,358:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:24,726:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:24,733:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:24,743:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:27,417:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:27,436:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:27,449:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:03:34,119:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:34,122:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:34,128:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:03:39,162:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:39,172:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:39,191:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:03:42,418:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:42,439:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:42,447:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:03:48,129:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:48,131:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:48,134:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:03:54,836:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:54,839:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:03:54,842:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:04:01,635:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:01,638:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:01,640:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:07,128:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:07,131:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:07,133:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:04:10,664:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:10,670:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:10,685:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:04:15,423:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:15,425:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:15,429:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:04:23,402:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:23,410:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:23,426:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:04:29,135:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:29,141:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:29,144:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:33,901:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:33,903:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:33,911:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:04:41,047:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:41,059:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:04:41,072:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:05:02,745:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:05:02,757:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:11:03,943:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:11:03,946:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:11:06,522:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:11:06,525:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:11:13,684:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:11:13,702:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:11:16,854:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:11:19,707:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:11:24,671:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:11:27,540:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:11:30,403:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:17:31,561:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:17:36,309:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:17:39,018:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:17:41,227:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:17:47,733:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:17:50,515:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:17:55,927:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:18:22,891:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:24:24,064:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:24:25,976:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:24:31,209:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:24:33,646:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:24:37,875:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:30:41,088:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:30:43,793:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:30:49,466:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:30:54,198:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:30:56,660:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:30:59,142:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:31:03,550:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:31:05,421:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:31:10,002:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:31:12,817:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:31:41,028:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2020-09-09 01:31:46,197:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:31:49,443:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n",
            "[WARNING] [2020-09-09 01:36:47,559:smac.runhistory.runhistory2epm.RunHistory2EPM4LogCost] Got cost of smaller/equal to 0. Replace by 0.000010 since we use log cost.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1LZO6KapUdz",
        "colab_type": "text"
      },
      "source": [
        "### Fazendo previsões na amostra de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCVyx6NNGAZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_target(data):\n",
        "    # data = (np.where(data==0, 'REABASTECER', data))\n",
        "    # data = (np.where(data==1, 'NORMAL', data))\n",
        "    data =  [ 'NORMAL' if x == 1 else 'REABASTECER' for x in data ]\n",
        "    return data"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzb-xipwpUd0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d9bcf80-0c9b-45fa-da9d-3ee3f0ec57a3"
      },
      "source": [
        "y_pred = dtc.predict(X_test)\n",
        "print(y_pred)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 0. ... 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SI5I4jbGdxS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a2278463-a30f-4680-9088-654ff744efdf"
      },
      "source": [
        "print(convert_target(y_pred))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'REABASTECER', 'NORMAL', 'REABASTECER', 'NORMAL', 'NORMAL', 'NORMAL']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aut6n5bHpUd4",
        "colab_type": "text"
      },
      "source": [
        "### Analisando a qualidade do modelo através da matriz de confusão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbkj_5r8pUd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHqxwz19pUeB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "93d80933-dfee-4b29-f4a6-e86d1578adfa"
      },
      "source": [
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['NORMAL', 'REABASTECER'])"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFcVGN07pUeE",
        "colab_type": "text"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoXNKUylpUeF",
        "colab_type": "text"
      },
      "source": [
        "## Scoring dos dados necessários para entregar a solução"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnuSodFQpUeF",
        "colab_type": "text"
      },
      "source": [
        "Como entrega da sua solução, esperamos os resultados classificados no seguinte dataset chamado \"to_be_scored.csv\":"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZtBhHqYpUeG",
        "colab_type": "text"
      },
      "source": [
        "### Download da \"folha de respostas\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "d4tcuzShpUeG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "d0b28235-3642-4f76-ed3f-5bfaa17f41e9"
      },
      "source": [
        "!wget --no-check-certificate --content-disposition https://gitlab.com/JoaoPedroPP/datasets/-/raw/master/ntn/to_be_scored.csv\n",
        "df_to_be_scored = pd.read_csv(r'to_be_scored.csv')\n",
        "df_to_be_scored.tail()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-09 01:36:57--  https://gitlab.com/JoaoPedroPP/datasets/-/raw/master/ntn/to_be_scored.csv\n",
            "Resolving gitlab.com (gitlab.com)... 172.65.251.78, 2606:4700:90:0:f22e:fbec:5bed:a9b9\n",
            "Connecting to gitlab.com (gitlab.com)|172.65.251.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‘to_be_scored.csv’\n",
            "\n",
            "to_be_scored.csv        [ <=>                ]  68.64K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-09-09 01:36:57 (5.10 MB/s) - ‘to_be_scored.csv’ saved [70291]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tempo</th>\n",
              "      <th>Estação</th>\n",
              "      <th>LAT</th>\n",
              "      <th>LONG</th>\n",
              "      <th>Movimentação</th>\n",
              "      <th>Original_473</th>\n",
              "      <th>Original_269</th>\n",
              "      <th>Zero</th>\n",
              "      <th>Maçã-Verde</th>\n",
              "      <th>Tangerina</th>\n",
              "      <th>Citrus</th>\n",
              "      <th>Açaí-Guaraná</th>\n",
              "      <th>Pêssego</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>979</th>\n",
              "      <td>2019-8-19</td>\n",
              "      <td>Hospital São Paulo</td>\n",
              "      <td>-23.5984</td>\n",
              "      <td>-46.6455</td>\n",
              "      <td>26787</td>\n",
              "      <td>34</td>\n",
              "      <td>65</td>\n",
              "      <td>28</td>\n",
              "      <td>17</td>\n",
              "      <td>33</td>\n",
              "      <td>27</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>980</th>\n",
              "      <td>2019-8-20</td>\n",
              "      <td>Hospital São Paulo</td>\n",
              "      <td>-23.5984</td>\n",
              "      <td>-46.6455</td>\n",
              "      <td>26629</td>\n",
              "      <td>21</td>\n",
              "      <td>60</td>\n",
              "      <td>18</td>\n",
              "      <td>15</td>\n",
              "      <td>27</td>\n",
              "      <td>22</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981</th>\n",
              "      <td>2019-8-21</td>\n",
              "      <td>Hospital São Paulo</td>\n",
              "      <td>-23.5984</td>\n",
              "      <td>-46.6455</td>\n",
              "      <td>27517</td>\n",
              "      <td>9</td>\n",
              "      <td>56</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>21</td>\n",
              "      <td>17</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>982</th>\n",
              "      <td>2019-8-22</td>\n",
              "      <td>Hospital São Paulo</td>\n",
              "      <td>-23.5984</td>\n",
              "      <td>-46.6455</td>\n",
              "      <td>26860</td>\n",
              "      <td>86</td>\n",
              "      <td>49</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>17</td>\n",
              "      <td>12</td>\n",
              "      <td>33</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>2019-8-23</td>\n",
              "      <td>Hospital São Paulo</td>\n",
              "      <td>-23.5984</td>\n",
              "      <td>-46.6455</td>\n",
              "      <td>24571</td>\n",
              "      <td>74</td>\n",
              "      <td>41</td>\n",
              "      <td>65</td>\n",
              "      <td>8</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Tempo             Estação      LAT  ...  Citrus  Açaí-Guaraná  Pêssego\n",
              "979  2019-8-19  Hospital São Paulo -23.5984  ...      27             6        2\n",
              "980  2019-8-20  Hospital São Paulo -23.5984  ...      22            43       43\n",
              "981  2019-8-21  Hospital São Paulo -23.5984  ...      17            37       37\n",
              "982  2019-8-22  Hospital São Paulo -23.5984  ...      12            33       33\n",
              "983  2019-8-23  Hospital São Paulo -23.5984  ...       7            27       27\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty_0LOZrpUeK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "dec82372-b20b-496e-9e7a-c9b0276393c1"
      },
      "source": [
        "df_to_be_scored = pd.read_csv('to_be_scored.csv')\n",
        "df_to_be_scored.tail()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tempo</th>\n",
              "      <th>Estação</th>\n",
              "      <th>LAT</th>\n",
              "      <th>LONG</th>\n",
              "      <th>Movimentação</th>\n",
              "      <th>Original_473</th>\n",
              "      <th>Original_269</th>\n",
              "      <th>Zero</th>\n",
              "      <th>Maçã-Verde</th>\n",
              "      <th>Tangerina</th>\n",
              "      <th>Citrus</th>\n",
              "      <th>Açaí-Guaraná</th>\n",
              "      <th>Pêssego</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>979</th>\n",
              "      <td>2019-8-19</td>\n",
              "      <td>Hospital São Paulo</td>\n",
              "      <td>-23.5984</td>\n",
              "      <td>-46.6455</td>\n",
              "      <td>26787</td>\n",
              "      <td>34</td>\n",
              "      <td>65</td>\n",
              "      <td>28</td>\n",
              "      <td>17</td>\n",
              "      <td>33</td>\n",
              "      <td>27</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>980</th>\n",
              "      <td>2019-8-20</td>\n",
              "      <td>Hospital São Paulo</td>\n",
              "      <td>-23.5984</td>\n",
              "      <td>-46.6455</td>\n",
              "      <td>26629</td>\n",
              "      <td>21</td>\n",
              "      <td>60</td>\n",
              "      <td>18</td>\n",
              "      <td>15</td>\n",
              "      <td>27</td>\n",
              "      <td>22</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981</th>\n",
              "      <td>2019-8-21</td>\n",
              "      <td>Hospital São Paulo</td>\n",
              "      <td>-23.5984</td>\n",
              "      <td>-46.6455</td>\n",
              "      <td>27517</td>\n",
              "      <td>9</td>\n",
              "      <td>56</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>21</td>\n",
              "      <td>17</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>982</th>\n",
              "      <td>2019-8-22</td>\n",
              "      <td>Hospital São Paulo</td>\n",
              "      <td>-23.5984</td>\n",
              "      <td>-46.6455</td>\n",
              "      <td>26860</td>\n",
              "      <td>86</td>\n",
              "      <td>49</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>17</td>\n",
              "      <td>12</td>\n",
              "      <td>33</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>2019-8-23</td>\n",
              "      <td>Hospital São Paulo</td>\n",
              "      <td>-23.5984</td>\n",
              "      <td>-46.6455</td>\n",
              "      <td>24571</td>\n",
              "      <td>74</td>\n",
              "      <td>41</td>\n",
              "      <td>65</td>\n",
              "      <td>8</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Tempo             Estação      LAT  ...  Citrus  Açaí-Guaraná  Pêssego\n",
              "979  2019-8-19  Hospital São Paulo -23.5984  ...      27             6        2\n",
              "980  2019-8-20  Hospital São Paulo -23.5984  ...      22            43       43\n",
              "981  2019-8-21  Hospital São Paulo -23.5984  ...      17            37       37\n",
              "982  2019-8-22  Hospital São Paulo -23.5984  ...      12            33       33\n",
              "983  2019-8-23  Hospital São Paulo -23.5984  ...       7            27       27\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtPhEnG3rXRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "21af32ee-a4cb-4174-c248-b5bd3638c9ad"
      },
      "source": [
        "df_to_be_scored.info()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 984 entries, 0 to 983\n",
            "Data columns (total 13 columns):\n",
            "Tempo           984 non-null object\n",
            "Estação         984 non-null object\n",
            "LAT             984 non-null float64\n",
            "LONG            984 non-null float64\n",
            "Movimentação    984 non-null int64\n",
            "Original_473    984 non-null int64\n",
            "Original_269    984 non-null int64\n",
            "Zero            984 non-null int64\n",
            "Maçã-Verde      984 non-null int64\n",
            "Tangerina       984 non-null int64\n",
            "Citrus          984 non-null int64\n",
            "Açaí-Guaraná    984 non-null int64\n",
            "Pêssego         984 non-null int64\n",
            "dtypes: float64(2), int64(9), object(2)\n",
            "memory usage: 100.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD1oFx5ypUeP",
        "colab_type": "text"
      },
      "source": [
        "# Atenção!\n",
        "\n",
        "O dataframe ``to_be_scored`` é a sua \"folha de respostas\". Note que a coluna \"TARGET\" não existe nessa amostra, que não pode ser então utilizada para treino de modelos de aprendizado supervisionado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bvJ-ycMLpUeQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "826ce022-6f86-49c5-b45b-67cb595184b4"
      },
      "source": [
        "df_to_be_scored.info()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 984 entries, 0 to 983\n",
            "Data columns (total 13 columns):\n",
            "Tempo           984 non-null object\n",
            "Estação         984 non-null object\n",
            "LAT             984 non-null float64\n",
            "LONG            984 non-null float64\n",
            "Movimentação    984 non-null int64\n",
            "Original_473    984 non-null int64\n",
            "Original_269    984 non-null int64\n",
            "Zero            984 non-null int64\n",
            "Maçã-Verde      984 non-null int64\n",
            "Tangerina       984 non-null int64\n",
            "Citrus          984 non-null int64\n",
            "Açaí-Guaraná    984 non-null int64\n",
            "Pêssego         984 non-null int64\n",
            "dtypes: float64(2), int64(9), object(2)\n",
            "memory usage: 100.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FGQcb_VpUeT",
        "colab_type": "text"
      },
      "source": [
        "<hr>\n",
        "\n",
        "# Atenção!\n",
        "\n",
        "# Para poder aplicar seu modelo e classificar a folha de respostas, você precisa primeiro aplicar as mesmas transformações com colunas que você aplicou no dataset de treino.\n",
        "\n",
        "# Não remova ou adicione linhas na folha de respostas. \n",
        "\n",
        "# Não altere a ordem das linhas na folha de respostas.\n",
        "\n",
        "# Ao final, as 1000 entradas devem estar classificadas, com os valores previstos em uma coluna chamada \"target\"\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBiPIh67pUeU",
        "colab_type": "text"
      },
      "source": [
        "Na célula abaixo, repetimos rapidamente os mesmos passos de pré-processamento usados no exemplo dado com árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnHb7B3mpUeU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bd4e6a96-f538-47bb-876d-03ef1d531cde"
      },
      "source": [
        "# 1 - Removendo linhas com valores NaN\n",
        "df_to_be_scored_1 = df_to_be_scored.dropna(axis='index', how='any', subset=['Tempo', 'Estação', 'LAT', 'LONG', 'Movimentação', 'Original_473', 'Original_269', 'Zero', 'Maçã-Verde', 'Tangerina', 'Citrus', 'Açaí-Guaraná', 'Pêssego'])\n",
        "\n",
        "# 2 - Inputando zeros nos valores faltantes\n",
        "impute_zeros.fit(X=df_to_be_scored_1)\n",
        "df_to_be_scored_2 = pd.DataFrame.from_records(\n",
        "    data=impute_zeros.transform(\n",
        "        X=df_to_be_scored_1\n",
        "    ),\n",
        "    columns=df_to_be_scored_1.columns\n",
        ")\n",
        "\n",
        "# 3 - Remoção de colunas\n",
        "df_to_be_scored_3 = df_to_be_scored_2.drop(columns=['Tempo', 'Estação', 'LAT', 'LONG', 'Movimentação'], inplace=False)\n",
        "\n",
        "# 4 - Encoding com \"dummy variables\" (se necessário)\n",
        "# df_to_be_scored_4 = pd.get_dummies(df_to_be_scored_3, columns=['Váriavel com dummy'])\n",
        "df_to_be_scored_4 = df_to_be_scored_3\n",
        "\n",
        "df_to_be_scored_4.tail()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Original_473</th>\n",
              "      <th>Original_269</th>\n",
              "      <th>Zero</th>\n",
              "      <th>Maçã-Verde</th>\n",
              "      <th>Tangerina</th>\n",
              "      <th>Citrus</th>\n",
              "      <th>Açaí-Guaraná</th>\n",
              "      <th>Pêssego</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>979</th>\n",
              "      <td>34</td>\n",
              "      <td>65</td>\n",
              "      <td>28</td>\n",
              "      <td>17</td>\n",
              "      <td>33</td>\n",
              "      <td>27</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>980</th>\n",
              "      <td>21</td>\n",
              "      <td>60</td>\n",
              "      <td>18</td>\n",
              "      <td>15</td>\n",
              "      <td>27</td>\n",
              "      <td>22</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981</th>\n",
              "      <td>9</td>\n",
              "      <td>56</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>21</td>\n",
              "      <td>17</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>982</th>\n",
              "      <td>86</td>\n",
              "      <td>49</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>17</td>\n",
              "      <td>12</td>\n",
              "      <td>33</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>74</td>\n",
              "      <td>41</td>\n",
              "      <td>65</td>\n",
              "      <td>8</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Original_473  Original_269  Zero  ...  Citrus  Açaí-Guaraná  Pêssego\n",
              "979            34            65    28  ...      27             6        2\n",
              "980            21            60    18  ...      22            43       43\n",
              "981             9            56    13  ...      17            37       37\n",
              "982            86            49     7  ...      12            33       33\n",
              "983            74            41    65  ...       7            27       27\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-34r7CzpUea",
        "colab_type": "text"
      },
      "source": [
        "<hr>\n",
        "\n",
        "Pode ser verificado abaixo que as colunas da folha de resposta agora são idênticas às que foram usadas para treinar o modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFBxmaRapUea",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d2e9796c-c856-4303-807c-7c7066880e89"
      },
      "source": [
        "df_training[\n",
        "    [\n",
        "        'Original_473', 'Original_269', 'Zero', 'Maçã-Verde', 'Tangerina',\n",
        "       'Citrus', 'Açaí-Guaraná', 'Pêssego'\n",
        "    ]\n",
        "].columns"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Original_473', 'Original_269', 'Zero', 'Maçã-Verde', 'Tangerina',\n",
              "       'Citrus', 'Açaí-Guaraná', 'Pêssego'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h93Gs1jIpUef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c8c5ed98-2dcb-4e21-8d39-85fff4b57296"
      },
      "source": [
        "df_to_be_scored_4.columns"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Original_473', 'Original_269', 'Zero', 'Maçã-Verde', 'Tangerina',\n",
              "       'Citrus', 'Açaí-Guaraná', 'Pêssego'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5i3Qq2TpUei",
        "colab_type": "text"
      },
      "source": [
        "# Atenção\n",
        "\n",
        "Para todas colunas que não existirem no \"df_to_be_scored\", você pode usar a técnica abaixo para adicioná-las:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "SYcy3BwppUei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7abf630e-1c7c-40c0-9fc2-66e9f0690b87"
      },
      "source": [
        "y_pred = dtc.predict(df_to_be_scored_4)\n",
        "df_to_be_scored_4['TARGET'] = convert_target(y_pred)\n",
        "df_to_be_scored_4.tail()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Original_473</th>\n",
              "      <th>Original_269</th>\n",
              "      <th>Zero</th>\n",
              "      <th>Maçã-Verde</th>\n",
              "      <th>Tangerina</th>\n",
              "      <th>Citrus</th>\n",
              "      <th>Açaí-Guaraná</th>\n",
              "      <th>Pêssego</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>979</th>\n",
              "      <td>34</td>\n",
              "      <td>65</td>\n",
              "      <td>28</td>\n",
              "      <td>17</td>\n",
              "      <td>33</td>\n",
              "      <td>27</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>980</th>\n",
              "      <td>21</td>\n",
              "      <td>60</td>\n",
              "      <td>18</td>\n",
              "      <td>15</td>\n",
              "      <td>27</td>\n",
              "      <td>22</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981</th>\n",
              "      <td>9</td>\n",
              "      <td>56</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>21</td>\n",
              "      <td>17</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>982</th>\n",
              "      <td>86</td>\n",
              "      <td>49</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>17</td>\n",
              "      <td>12</td>\n",
              "      <td>33</td>\n",
              "      <td>33</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>74</td>\n",
              "      <td>41</td>\n",
              "      <td>65</td>\n",
              "      <td>8</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Original_473  Original_269  Zero  ...  Açaí-Guaraná  Pêssego  TARGET\n",
              "979            34            65    28  ...             6        2  NORMAL\n",
              "980            21            60    18  ...            43       43  NORMAL\n",
              "981             9            56    13  ...            37       37  NORMAL\n",
              "982            86            49     7  ...            33       33  NORMAL\n",
              "983            74            41    65  ...            27       27  NORMAL\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fJcEVZspUem",
        "colab_type": "text"
      },
      "source": [
        "### Salvando a folha de respostas como um arquivo .csv para ser submetido"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwUvjqYXrmKI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fdb81eb-7bba-4c1d-8b9f-6de8ccde4a9b"
      },
      "source": [
        "df_to_be_scored_4.shape"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(984, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgkqMLh7pUem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_to_be_scored_4.to_csv('/content/drive/My Drive/results.csv',index=False)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqTsM5e6pUeq",
        "colab_type": "text"
      },
      "source": [
        "# Atenção\n",
        "\n",
        "# A execução da célula acima irá criar um novo \"data asset\" no seu projeto no Watson Studio. Você precisará realizar o download deste arquivo juntamente com este notebook e criar um arquivo zip com os arquivos **results.csv** e **notebook.ipynb** para submissão. (os arquivos devem estar nomeados desta forma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHMzQXznpUeq",
        "colab_type": "text"
      },
      "source": [
        "<hr>\n",
        "\n",
        "## Parabéns!\n",
        "\n",
        "Se você já está satisfeito com a sua solução, vá até a página abaixo e envie os arquivos necessários para submissão.\n",
        "\n",
        "# https://tnt.maratona.dev\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKX5SgBepUer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 126,
      "outputs": []
    }
  ]
}